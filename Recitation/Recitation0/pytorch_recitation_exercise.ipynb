{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise for introduction to PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT NOTE: To avoid version mismatch errors with Autolab, please ensure you are using commands that are from the following versions of [*NumPy*](https://numpy.org/) and [*Torch*](https://pytorch.org/) :    \n",
    "`numpy==1.16.4`  \n",
    "`torch==1.2.0`  \n",
    "if your installation fails, make sure you are using a virtual environment with `python v3.7.13` installed\n",
    "  \n",
    "For example, \n",
    "Consider using `torch.mul(x, y)` instead of `torch.multiply(x, y)`. \n",
    "\n",
    "Why? `torch.mul(x, y)` is available in version `torch==1.2.0`, whereas `torch.multiply(x, y)` is not. Using `torch==1.2.0` will help us avoid unpleasant issues with AutoLab's default versioning.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> PyTorch is an open source deep learning platform that provides a seamless path from research prototyping to production deployment.\n",
    "> - *Hybrid Front-End:* A new hybrid front-end seamlessly transitions between eager mode and graph mode to provide both flexibility and speed.\n",
    "> - *Distributed Training:* Scalable distributed training and performance optimization in research and production is enabled by the torch.distributed backend.\n",
    "> - *Python-First:* Deep integration into Python allows popular libraries and packages to be used for easily writing neural network layers in Python.\n",
    "> - *Tools & Libraries:* A rich ecosystem of tools and libraries extends PyTorch and supports development in computer vision, NLP and more.\n",
    ">\n",
    "> —*[About PyTorch](https://pytorch.org/)*\n",
    "\n",
    "One consideration as to why we are using PyTorch is most succinctly summerized by Andrej Karpathy, Former Director of Artificial Intelligence and Autopilot Vision at Tesla. The technical summary can be found [here](https://twitter.com/karpathy/status/868178954032513024?lang=en).\n",
    "\n",
    "You also refer a brief summary on PyTorch by Nvidia [here](https://www.nvidia.com/en-us/glossary/data-science/pytorch/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.5\n",
      "1.7.1+cu101\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "# Expected outputs:\n",
    "# 1.16.4\n",
    "# 1.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Interconversion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Converting from NumPy to PyTorch Tensor\n",
    "In this task, you will implement a conversion function from arrays to tensors.\n",
    "\n",
    "The function should take a numpy ndarray and convert it to a PyTorch tensor.\n",
    "\n",
    "*Function torch.tensor is one of the simple ways to implement it but please do not use it this time. The PyTorch environment installed on Autolab is not an up-to-date version and does not support this function.*\n",
    "\n",
    "**Your Task**: Implement the function `numpy2tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy2tensor(x):\n",
    "    \"\"\"\n",
    "    Creates a torch.Tensor from a numpy.ndarray.\n",
    "\n",
    "    Parameters: \n",
    "    x (numpy.ndarray): 1-dimensional numpy array.\n",
    "\n",
    "    Returns: \n",
    "    torch.Tensor: 1-dimensional torch tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    return  torch.tensor(x) #NotImplemented   # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "\n",
    "print(type(numpy2tensor(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt> &lt;class &#39;torch.Tensor&#39;&gt; </tt></td> \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Converting from PyTorch Tensor to NumPy\n",
    "\n",
    "In this task, you will implement a conversion function from tensors to arrays.\n",
    "\n",
    "The function should take a PyTorch tensor and convert it to a numpy ndarray.\n",
    "\n",
    "**Your Task**: Implement the function `tensor2numpy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2numpy(x):\n",
    "    \"\"\"\n",
    "    Creates a numpy.ndarray from a torch.Tensor.\n",
    "\n",
    "    Parameters:\n",
    "    x (torch.Tensor): 1-dimensional torch tensor.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: 1-dimensional numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    return  x.numpy()  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "X = torch.from_numpy(X)\n",
    "\n",
    "print(type(tensor2numpy(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt> &lt;class &#39;numpy.ndarray&#39;&gt; </tt></td> \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Vectorization**\n",
    "\n",
    "Lists are a foundational data structure in Python, allowing us to create simple and complex algorithms to solve problems. However, in mathematics and particularly in linear algebra, we work with vectors and matrices to model problems and create statistical solutions. Through these exercises, we will begin introducing you to how to think more mathematically through the use of PyTorch by starting with a process known as vectorization.\n",
    "\n",
    "Index chasing is a very valuable skill, and certainly one you will need in this course, but mathematical problems often have simpler and more efficient representations that use vectors. The process of converting from an implimentation that uses indicies to one that uses vectors is known as vectorization. Once vectorized, the resulting implementation often yields to the user faster and more readable code than before.\n",
    "\n",
    "In the following problems, we will ask you to practice reading mathematical expressions and deduce their vectorized equivalent along with their implementation in Python. You will use the PyTorch array object as the Python equivalent to a vector, and in later sections you will work with sets of vectors known as matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_dot(x, y):\n",
    "    \"\"\"\n",
    "    Dot product of two tensors.\n",
    "\n",
    "    Parameters: \n",
    "    x (torch.Tensor): 1-dimensional torch tensor.\n",
    "    y (torch.Tensor): 1-dimensional torch tensor.\n",
    "\n",
    "    Returns: \n",
    "    torch.int64: scalar quantity.\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.dot(x,y)   # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7082791, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "Y = np.random.randint(-1000, 1000, size=3000)\n",
    "\n",
    "\n",
    "X = numpy2tensor(X)\n",
    "Y = numpy2tensor(Y)\n",
    "\n",
    "print(PYTORCH_dot(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_dot(X,Y) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt> 7082791 </tt></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Outer Product\n",
    "\n",
    "In this task, you will implement the outer product function for torch tensors.\n",
    "\n",
    "The outer product (also known as the tensor product) of vectors x and y is defined as\n",
    "\n",
    "$$\n",
    "x \\otimes y =\n",
    "\\begin{bmatrix}\n",
    "x_1 y_1 & x_1 y_2 & … & x_1 y_n\\\\\n",
    "x_2 y_1 & x_2 y_2 & … & x_2 y_n\\\\\n",
    "⋮ & ⋮ & ⋱ & ⋮ \\\\\n",
    "x_m y_1 & x_m y_2 & … & x_m y_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Your Task**: Implement the function `PYTORCH_outer`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_outer(x, y):\n",
    "    \"\"\"\n",
    "    Compute the outer product of two vectors.\n",
    "\n",
    "    Parameters: \n",
    "    x (torch.Tensor): 1-dimensional torch tensor.\n",
    "    y (torch.Tensor): 1-dimensional torch tensor.\n",
    "\n",
    "    Returns: \n",
    "    torch.Tensor: 2-dimensional torch tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.ger(x, y)   # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  59092, -144096,  136512,  ...,  -53088,  -86268,   53404],\n",
      "        [  82467, -201096,  190512,  ...,  -74088, -120393,   74529],\n",
      "        [-122111,  297768, -282096,  ...,  109704,  178269, -110357],\n",
      "        ...,\n",
      "        [-144551,  352488, -333936,  ...,  129864,  211029, -130637],\n",
      "        [-179707,  438216, -415152,  ...,  161448,  262353, -162409],\n",
      "        [  88825, -216600,  205200,  ...,  -79800, -129675,   80275]],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "Y = np.random.randint(-1000, 1000, size=3000)\n",
    "\n",
    "\n",
    "X = numpy2tensor(X)\n",
    "Y = numpy2tensor(Y)\n",
    "\n",
    "print(PYTORCH_outer(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        </tt></td> \n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_outer(X,Y) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt> \n",
    "            [[&nbsp;&nbsp;59092&nbsp;-144096&nbsp;&nbsp;136512&nbsp;...&nbsp;&nbsp;-53088&nbsp;&nbsp;-86268&nbsp;&nbsp;&nbsp;53404] <br>\n",
    "            &nbsp;[&nbsp;&nbsp;82467&nbsp;-201096&nbsp;&nbsp;190512&nbsp;...&nbsp;&nbsp;-74088&nbsp;-120393&nbsp;&nbsp;&nbsp;74529] <br>\n",
    "            &nbsp;[-122111&nbsp;&nbsp;297768&nbsp;-282096&nbsp;...&nbsp;&nbsp;109704&nbsp;&nbsp;178269&nbsp;-110357] <br>\n",
    "            &nbsp;... <br>\n",
    "            &nbsp;[-144551&nbsp;&nbsp;352488&nbsp;-333936&nbsp;...&nbsp;&nbsp;129864&nbsp;&nbsp;211029&nbsp;-130637] <br>\n",
    "            &nbsp;[-179707&nbsp;&nbsp;438216&nbsp;-415152&nbsp;...&nbsp;&nbsp;161448&nbsp;&nbsp;262353&nbsp;-162409] <br>\n",
    "            &nbsp;[&nbsp;&nbsp;88825&nbsp;-216600&nbsp;&nbsp;205200&nbsp;...&nbsp;&nbsp;-79800&nbsp;-129675&nbsp;&nbsp;&nbsp;80275]] <br>\n",
    "        </tt></td> \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Hadamard Product\n",
    "\n",
    "In this task, you will implement the Hadamard product function, `multiply`, for torch tensors.\n",
    "\n",
    "The Hadamard product (also known as the Schur product or entrywise product) of vectors x and y is defined as\n",
    "\n",
    "$$\n",
    "x \\circ y =\n",
    "\\begin{bmatrix}\n",
    "x_{1} y_{1} & x_{2} y_{2} & … & x_{n} y_{n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Your Task**: Implement the function `PYTORCH_multiply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_multiply(x, y):\n",
    "    \"\"\"\n",
    "    Multiply arguments element-wise.\n",
    "\n",
    "    Parameters: \n",
    "    x (torch.Tensor): 1-dimensional torch tensor.\n",
    "    y (torch.Tensor): 1-dimensional torch tensor.\n",
    "\n",
    "    Returns: \n",
    "    torch.Tensor: 1-dimensional torch tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    return x*y   # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  59092, -201096, -282096,  ...,  129864,  262353,   80275],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "Y = np.random.randint(-1000, 1000, size=3000)\n",
    "\n",
    "\n",
    "X = numpy2tensor(X)\n",
    "Y = numpy2tensor(Y)\n",
    "\n",
    "print(PYTORCH_multiply(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_multiply(X,Y) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt>\n",
    "            [&nbsp;&nbsp;59092&nbsp;-201096&nbsp;-282096&nbsp;...&nbsp;&nbsp;129864&nbsp;&nbsp;262353&nbsp;&nbsp;&nbsp;80275]\n",
    "        </tt></td> \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Sum-Product\n",
    "In this task, you will implement the sum-product function for torch tensors.\n",
    "\n",
    "The sum-product of vectors x and y, each with n real component, is defined as \n",
    "\n",
    "$$\n",
    "f(x, y) = \n",
    "{\n",
    "\\begin{bmatrix}\n",
    "1\\\\\n",
    "1\\\\\n",
    "⋮\\\\\n",
    "1\n",
    "\\end{bmatrix}^{\\;T}\n",
    "%\n",
    "\\begin{bmatrix}\n",
    "x_1 y_1 & x_1 y_2 & … & x_1 y_n\\\\\n",
    "x_2 y_1 & x_2 y_2 & … & x_2 y_n\\\\\n",
    "⋮ & ⋮ & ⋱ & ⋮ \\\\\n",
    "x_m y_1 & x_m y_2 & … & x_m y_n\n",
    "\\end{bmatrix}\n",
    "%\n",
    "\\begin{bmatrix}\n",
    "1\\\\\n",
    "1\\\\\n",
    "⋮\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "} = \n",
    "\\displaystyle\\sum_{i=1}^{n} \\displaystyle\\sum_{j=1}^{n} x_i \\cdot y_j\n",
    "$$\n",
    "\n",
    "**Your Task**: Implement the function `PYTORCH_sumproduct`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_sumproduct(x, y):\n",
    "    \"\"\"\n",
    "    Sum over all the dimensions of the outer product of two vectors.\n",
    "\n",
    "    Parameters: \n",
    "    x (torch.Tensor): 1-dimensional torch tensor.\n",
    "    y (torch.Tensor): 1-dimensional torch tensor.\n",
    "\n",
    "    Returns: \n",
    "    torch.int64: scalar quantity.\n",
    "    \"\"\"\n",
    "    \n",
    "    return  torch.sum(torch.ger(x, y))   # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(265421520)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "Y = np.random.randint(-1000, 1000, size=3000)\n",
    "\n",
    "X = numpy2tensor(X)\n",
    "Y = numpy2tensor(Y)\n",
    "\n",
    "print(PYTORCH_sumproduct(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt><b> TORCH_sumproduct(X,Y) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt> 265421520 </tt></td> \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 ReLU\n",
    "\n",
    "In this task, you will implement the ReLU activation function torch tensors.\n",
    "\n",
    "The ReLU activation (also known as the rectifier or rectified linear unit) matrix Z resulting from applying the ReLU function to matrix X is defined such that for $X,Z \\in M_{m \\times n} (\\mathbb{R})$, \n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_ReLU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_ReLU(x):\n",
    "    \"\"\"\n",
    "    Applies the rectified linear unit function element-wise.\n",
    "\n",
    "    Parameters: \n",
    "    x (torch.Tensor): 2-dimensional torch tensor.\n",
    "\n",
    "    Returns: \n",
    "    torch.Tensor: 2-dimensional torch tensor.\n",
    "    \"\"\"\n",
    " \n",
    "    return torch.relu(x)   # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   0, 653,  ..., 773, 961,   0],\n",
      "        [  0, 456,   0,  ..., 168, 273,   0],\n",
      "        [936, 475,   0,  ..., 408,   0,   0],\n",
      "        ...,\n",
      "        [  0, 396, 457,  ..., 646,   0,   0],\n",
      "        [645, 943,   0,  ..., 863,   0, 790],\n",
      "        [641,   0, 379,  ..., 347,   0,   0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=(3000,3000))\n",
    "\n",
    "\n",
    "X = numpy2tensor(X)\n",
    "\n",
    "print(PYTORCH_ReLU(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        </tt></td> \n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_ReLU(X) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt>\n",
    "            [[&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0&nbsp;653&nbsp;...&nbsp;773&nbsp;961&nbsp;&nbsp;&nbsp;0] <br>\n",
    "&nbsp;[&nbsp;&nbsp;0&nbsp;456&nbsp;&nbsp;&nbsp;0&nbsp;...&nbsp;168&nbsp;273&nbsp;&nbsp;&nbsp;0] <br>\n",
    "&nbsp;[936&nbsp;475&nbsp;&nbsp;&nbsp;0&nbsp;...&nbsp;408&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0] <br>\n",
    "&nbsp;... <br>\n",
    "&nbsp;[&nbsp;&nbsp;0&nbsp;396&nbsp;457&nbsp;...&nbsp;646&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0] <br>\n",
    "&nbsp;[645&nbsp;943&nbsp;&nbsp;&nbsp;0&nbsp;...&nbsp;863&nbsp;&nbsp;&nbsp;0&nbsp;790] <br>\n",
    "&nbsp;[641&nbsp;&nbsp;&nbsp;0&nbsp;379&nbsp;...&nbsp;347&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;0]]\n",
    "        </tt></td> \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Prime ReLU (derivative of ReLU)\n",
    "\n",
    "In this task, you will implement the derivative of the ReLU activation function for torch tensors.\n",
    "\n",
    "The derivative of the ReLU activation matrix Z resulting from applying the derivative of the ReLU function to matrix X is defined such that for $X,Z \\in M_{m \\times n} (\\mathbb{R})$, \n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_PrimeReLU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_PrimeReLU(x):\n",
    "    \"\"\"\n",
    "    Applies the derivative of the rectified linear unit function \n",
    "    element-wise.\n",
    "\n",
    "    Parameters: \n",
    "    x (numpy.ndarray): 2-dimensional torch tensor.\n",
    "\n",
    "    Returns: \n",
    "    numpy.ndarray: 2-dimensional torch tensor.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    # 创建一个与 x 形状相同的零张量\n",
    "    gradient = torch.zeros_like(x)\n",
    "\n",
    "    # 设置所有 x 中正数位置的梯度为 1\n",
    "    gradient[x > 0] = 1\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1,  ..., 1, 1, 0],\n",
      "        [0, 1, 0,  ..., 1, 1, 0],\n",
      "        [1, 1, 0,  ..., 1, 0, 0],\n",
      "        ...,\n",
      "        [0, 1, 1,  ..., 1, 0, 0],\n",
      "        [1, 1, 0,  ..., 1, 0, 1],\n",
      "        [1, 0, 1,  ..., 1, 0, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=(3000,3000))\n",
    "\n",
    "X = numpy2tensor(X)\n",
    "\n",
    "print(PYTORCH_PrimeReLU(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_PrimeReLU(X) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt>\n",
    "            [[0&nbsp;0&nbsp;1&nbsp;...&nbsp;1&nbsp;1&nbsp;0] <br>\n",
    "&nbsp;[0&nbsp;1&nbsp;0&nbsp;...&nbsp;1&nbsp;1&nbsp;0] <br>\n",
    "&nbsp;[1&nbsp;1&nbsp;0&nbsp;...&nbsp;1&nbsp;0&nbsp;0] <br>\n",
    "&nbsp;... <br>\n",
    "&nbsp;[0&nbsp;1&nbsp;1&nbsp;...&nbsp;1&nbsp;0&nbsp;0] <br>\n",
    "&nbsp;[1&nbsp;1&nbsp;0&nbsp;...&nbsp;1&nbsp;0&nbsp;1] <br>\n",
    "&nbsp;[1&nbsp;0&nbsp;1&nbsp;...&nbsp;1&nbsp;0&nbsp;0]]\n",
    "        </tt></td> \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Tensor Manipulation**\n",
    "\n",
    "PyTorch offers a wide range of tensor manipulation tasks that empower users to efficiently process and transform data within neural network workflows. \n",
    "These tasks include :\n",
    "1.  Flatten\n",
    "2.  Unsqueeze\n",
    "3.  Squeeze\n",
    "4.  Reshape\n",
    "5.  Transpose\n",
    "6.  Permute\n",
    "7.  Concatenation\n",
    "8.  Stack\n",
    "9.  Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Flatten\n",
    "\n",
    "In this task, you will implement the flatten function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_flatten`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_flatten(input_tensor):\n",
    "    \"\"\"\n",
    "    Reshapes a tensor into a 1-dimensional array while maintaining the order of elements.\n",
    "\n",
    "    Parameters: \n",
    "    x (torch.Tensor): 3-dimensional torch tensor.\n",
    "\n",
    "    Returns: \n",
    "    torch.Tensor: 1-dimensional torch tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    return input_tensor.flatten() #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  2,   5, -10,  ...,   1,   3,  -3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-10, 10, size=(100,100,100))\n",
    "\n",
    "X = numpy2tensor(X)\n",
    "\n",
    "print(PYTORCH_flatten(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_flatten(X) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt>\n",
    "            [  2,   5, -10,  ...,   1,   3,  -3]\n",
    "        </tt></td> \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Unsqueeze\n",
    "\n",
    "In this task, you will implement the unsqueeze function for torch tensors along given dimension.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_unsqueeze`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_unsqueeze(X,dim):\n",
    "    \"\"\"\n",
    "    Adds a new dimension to a tensor at the specified position 'dim'.\n",
    "\n",
    "    Parameters: \n",
    "    x (torch.Tensor): 2-dimensional torch tensor.\n",
    "\n",
    "    dim (int): scalar.\n",
    "\n",
    "    Returns: \n",
    "    torch.Tensor: 3-dimensional torch tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.unsqueeze(X, dim) #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4, 0, 3,  ..., 2, 2, 3],\n",
      "         [2, 3, 2,  ..., 2, 3, 3],\n",
      "         [1, 3, 4,  ..., 0, 2, 4],\n",
      "         ...,\n",
      "         [2, 0, 1,  ..., 4, 4, 3],\n",
      "         [2, 4, 3,  ..., 3, 0, 0],\n",
      "         [2, 3, 4,  ..., 4, 3, 1]]], dtype=torch.int32)\n",
      "\n",
      "\n",
      "Shape before unsqueeze:  torch.Size([100, 100])\n",
      "Shape after unsqueeze:  torch.Size([1, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 5, size=(100,100))\n",
    "\n",
    "X = numpy2tensor(X)\n",
    "\n",
    "print(PYTORCH_unsqueeze(X,0))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Shape before unsqueeze: \",X.shape)\n",
    "print(\"Shape after unsqueeze: \",PYTORCH_unsqueeze(X,0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_unsqueeze(X) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt>\n",
    "        [[[4&nbsp;0&nbsp;3&nbsp;...&nbsp;2&nbsp;2&nbsp;3] <br>\n",
    "&nbsp; [2&nbsp;3&nbsp;2&nbsp;...&nbsp;2&nbsp;3&nbsp;3] <br>\n",
    "&nbsp; [1&nbsp;3&nbsp;4&nbsp;...&nbsp;0&nbsp;2&nbsp;4] <br>\n",
    "&nbsp; ..., <br>\n",
    "&nbsp; [2&nbsp;0&nbsp;1&nbsp;...&nbsp;4&nbsp;4&nbsp;3] <br>\n",
    "&nbsp; [2&nbsp;4&nbsp;3&nbsp;...&nbsp;3&nbsp;0&nbsp;0] <br>\n",
    "&nbsp; [2&nbsp;3&nbsp;4&nbsp;...&nbsp;4&nbsp;3&nbsp;1]]]<br>\n",
    "<br>\n",
    "Shape before unsqueeze:  torch.Size([100, 100]) <br>\n",
    "Shape after unsqueeze:  torch.Size([1, 100, 100])\n",
    "        </tt></td> \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Squeeze\n",
    "\n",
    "In this task, you will implement the squeeze function for torch tensors along axis with dimension 1 (axis = 0).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_squeeze`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_squeeze(X,dim):\n",
    "    \"\"\"\n",
    "    Removes dimension to a tensor at the specified position 'dim'.\n",
    "\n",
    "    Parameters: \n",
    "    x (torch.Tensor): 2-dimensional torch tensor.\n",
    "\n",
    "    dim (integer): scalar.\n",
    "\n",
    "    Returns: \n",
    "    torch.Tensor: 1-dimensional torch tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.squeeze(X, dim) #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 0, 3, 3, 7], dtype=torch.int32)\n",
      "Shape of tensor before squeeze:  torch.Size([1, 5])\n",
      "Shape of tensor after squeeze:  torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 10, size=(1,5))\n",
    "\n",
    "X = numpy2tensor(X)\n",
    "\n",
    "\n",
    "\n",
    "print(PYTORCH_squeeze(X,0))\n",
    "\n",
    "print(\"Shape of tensor before squeeze: \",X.shape)\n",
    "print(\"Shape of tensor after squeeze: \",PYTORCH_squeeze(X,0).shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_squeeze(X) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt>\n",
    "        [5&nbsp;0&nbsp;3&nbsp;3&nbsp;7&nbsp;] <br>\n",
    "Shape of tensor before squeeze:  torch.Size([1, 5]) <br>\n",
    "Shape of tensor after squeeze:  torch.Size([5])\n",
    "        </tt></td> \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Reshape\n",
    "\n",
    "In this task, you will implement the reshape function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_reshape(X,new_shape):\n",
    "    \"\"\"\n",
    "    Reorganizes the tensor's elements to match a specified shape while maintaining the same number of elements.\n",
    "    \n",
    "    Parameters: \n",
    "    x (torch.Tensor): 3-dimensional torch tensor.\n",
    "\n",
    "    new_shape (tuple): tuple with 3 elements which represents the new shape of the tensor.\n",
    "\n",
    "    Returns: \n",
    "    torch.Tensor: torch tensor of dimension 'new_shape'.\n",
    "    \"\"\"\n",
    "    return X.reshape(new_shape) #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5, 0, 3, 3, 7],\n",
      "         [9, 3, 5, 2, 4],\n",
      "         [7, 6, 8, 8, 1]],\n",
      "\n",
      "        [[6, 7, 7, 8, 1],\n",
      "         [5, 9, 8, 9, 4],\n",
      "         [3, 0, 3, 5, 0]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 10, size=(3,10))\n",
    "\n",
    "X = numpy2tensor(X)\n",
    "\n",
    "\n",
    "\n",
    "print(PYTORCH_reshape(X,(2,3,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_reshape(X,new_shape) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt>\n",
    "             [[[5,&nbsp;0,&nbsp;3,&nbsp;3,&nbsp;7&nbsp;], <br>\n",
    "        &nbsp; [9,&nbsp;3,&nbsp;5,&nbsp;2,&nbsp;4&nbsp;], <br>\n",
    "        &nbsp; [7,&nbsp;6,&nbsp;8,&nbsp;8,&nbsp;1&nbsp;]], <br>\n",
    "        <br>\n",
    "        &nbsp;[[6,&nbsp;7,&nbsp;7,&nbsp;8,&nbsp;1&nbsp;], <br>\n",
    "        &nbsp; [5,&nbsp;9,&nbsp;8,&nbsp;9,&nbsp;4&nbsp;], <br>\n",
    "        &nbsp; [3,&nbsp;0,&nbsp;3,&nbsp;5,&nbsp;0&nbsp;]]] \n",
    "        \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Transpose\n",
    "\n",
    "In this task, you will implement the transpose function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_transpose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_transpose(X,dim0,dim1):\n",
    "    \"\"\"\n",
    "    Reorganizes the tensor's elements and shape effectively by swapping along given direction.\n",
    "    \n",
    "    Parameters: \n",
    "    x (torch.Tensor): 3-dimensional torch tensor.\n",
    "\n",
    "    dim0 (int): the first dimension to be transposed.\n",
    "\n",
    "    dim1 (int): the second dimension to be transposed.\n",
    "\n",
    "    Returns: \n",
    "    torch.Tensor: torch tensor of transposed version input.\n",
    "    \"\"\"\n",
    "    return torch.transpose(X, dim0, dim1) #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5, 7, 2],\n",
      "         [0, 9, 4],\n",
      "         [3, 3, 7],\n",
      "         [3, 5, 6]],\n",
      "\n",
      "        [[8, 7, 5],\n",
      "         [8, 7, 9],\n",
      "         [1, 8, 8],\n",
      "         [6, 1, 9]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 10, size=(2,3,4))\n",
    "\n",
    "X = numpy2tensor(X)\n",
    "\n",
    "\n",
    "print(PYTORCH_transpose(X,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_transpose(X,dim0,dim1) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt>\n",
    "             [[[5,&nbsp;7,&nbsp;2,], <br>\n",
    "        &nbsp; [0,&nbsp;9,&nbsp;4,], <br>\n",
    "        &nbsp; [3,&nbsp;3,&nbsp;7,], <br>\n",
    "        &nbsp; [3,&nbsp;5,&nbsp;6,]], <br>\n",
    "        <br>\n",
    "        &nbsp;[[8,&nbsp;7,&nbsp;5,], <br>\n",
    "        &nbsp; [8,&nbsp;7,&nbsp;9,], <br>\n",
    "        &nbsp; [1,&nbsp;8,&nbsp;8,], <br>\n",
    "        &nbsp; [6,&nbsp;1,&nbsp;9,]]] <br>\n",
    "        \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Permute\n",
    "\n",
    "In this task, you will implement the permute function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_permute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_permute(X,dims):\n",
    "    \"\"\"\n",
    "    Reorganizes the the dimensions of a tensor according to a specified permutation tuple while maintaining the data's order.\n",
    "    \n",
    "    Parameters: \n",
    "    x (torch.Tensor): 3-dimensional torch tensor.\n",
    "\n",
    "    dims (tuple): tuple of integers that represents axis to be permuted\n",
    "\n",
    "    Returns: \n",
    "    torch.Tensor: torch tensor of permuted version input.\n",
    "    \"\"\"\n",
    "    return X.permute(dims) #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5, 7, 2],\n",
      "         [8, 7, 5]],\n",
      "\n",
      "        [[0, 9, 4],\n",
      "         [8, 7, 9]],\n",
      "\n",
      "        [[3, 3, 7],\n",
      "         [1, 8, 8]],\n",
      "\n",
      "        [[3, 5, 6],\n",
      "         [6, 1, 9]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 10, size=(2,3,4))\n",
    "\n",
    "X = numpy2tensor(X)\n",
    "\n",
    "\n",
    "print(PYTORCH_permute(X,(2,0,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_permute(X,dims) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt>\n",
    "             [[[5,&nbsp;7,&nbsp;2,], <br>\n",
    "        &nbsp; [8,&nbsp;7,&nbsp;5,]], <br>\n",
    "        <br>\n",
    "        &nbsp;[[0,&nbsp;9,&nbsp;4,], <br>\n",
    "        &nbsp; [8,&nbsp;7,&nbsp;9,]], <br>\n",
    "        <br>\n",
    "        &nbsp;[[3,&nbsp;3,&nbsp;7,], <br>\n",
    "        &nbsp; [1,&nbsp;8,&nbsp;8,]], <br>\n",
    "        <br>\n",
    "        &nbsp;[[3,&nbsp;5,&nbsp;6,], <br>\n",
    "        &nbsp; [6,&nbsp;1,&nbsp;9,]]] <br>\n",
    "        \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Concatenate\n",
    "\n",
    "In this task, you will implement the Concatenate function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_concatenate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_concatenate(tensors,dim):\n",
    "    \"\"\"\n",
    "    Reorganizes the the dimensions of a tensor according to a specified permutation tuple while maintaining the data's order.\n",
    "    \n",
    "    Parameters: \n",
    "    tensors (tuple): tuple of Tensors with same shape except in concatenate dimension.\n",
    "\n",
    "    dim (int): concatenate dimension\n",
    "\n",
    "    Returns: \n",
    "    torch.Tensor: concatenated tensor.\n",
    "    \"\"\"\n",
    "    return torch.cat(tensors, dim) #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5, 0, 3, 3, 0, 0, 1],\n",
      "         [7, 9, 3, 5, 2, 0, 2],\n",
      "         [2, 4, 7, 6, 0, 1, 1]],\n",
      "\n",
      "        [[8, 8, 1, 6, 2, 0, 1],\n",
      "         [7, 7, 8, 1, 1, 1, 0],\n",
      "         [5, 9, 8, 9, 2, 0, 2]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 10, size=(2,3,4))\n",
    "Y = np.random.randint(0, 3, size=(2,3,3))\n",
    "X = numpy2tensor(X)\n",
    "Y = numpy2tensor(Y)\n",
    "\n",
    "\n",
    "print(PYTORCH_concatenate((X,Y),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_concatenate(tensors,dim) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt>\n",
    "            [[[5,&nbsp;0,&nbsp;3,&nbsp;3,&nbsp;0,&nbsp;0,&nbsp;1], <br>\n",
    "            &nbsp; [7,&nbsp;9,&nbsp;3,&nbsp;5,&nbsp;2,&nbsp;0,&nbsp;2], <br>\n",
    "            &nbsp; [2,&nbsp;4,&nbsp;7,&nbsp;6,&nbsp;0,&nbsp;1,&nbsp;1]],<br>\n",
    "            <br>\n",
    "            &nbsp;[[8,&nbsp;8,&nbsp;1,&nbsp;6,&nbsp;2,&nbsp;0,&nbsp;1], <br>\n",
    "            &nbsp; [7,&nbsp;7,&nbsp;8,&nbsp;1,&nbsp;1,&nbsp;1,&nbsp;0], <br>\n",
    "            &nbsp; [5,&nbsp;9,&nbsp;8,&nbsp;9,&nbsp;2,&nbsp;0,&nbsp;2]]],<br>\n",
    "       \n",
    "        \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8 Stack\n",
    "\n",
    "In this task, you will implement the stack function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_stack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_stack(tensors,dim):\n",
    "\n",
    "    \"\"\"\n",
    "    In contrast to Concatenation, which merges two tensors along an existing dimension,\n",
    "    Stack creates a new dimension to combine tensors.\n",
    "\n",
    "    Parameters:\n",
    "    tensors (tuple):  tuple of tensors to be stacked\n",
    "    dim (int): dimension to insert. \n",
    "\n",
    "    Returns: \n",
    "    torch.Tensor: stacked tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.stack(tensors, dim) #TODO\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5, 0, 3],\n",
      "         [1, 2, 0]],\n",
      "\n",
      "        [[3, 7, 9],\n",
      "         [2, 0, 0]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(0, 10, size=(2,3))\n",
    "Y = np.random.randint(0, 3, size=(2,3))\n",
    "X = numpy2tensor(X)\n",
    "Y = numpy2tensor(Y)\n",
    "\n",
    "\n",
    "print(PYTORCH_stack((X,Y),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_stack(tensors,dims) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt>\n",
    "            [[[5,&nbsp;0,&nbsp;3,], <br>\n",
    "        &nbsp; [1,&nbsp;2,&nbsp;0,]], <br>\n",
    "        <br>\n",
    "        &nbsp;[[3,&nbsp;7,&nbsp;9,], <br>\n",
    "        &nbsp; [2,&nbsp;0,&nbsp;0,]]], <br>\n",
    "        <br>\n",
    "        \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9 Padding\n",
    "\n",
    "In this task, you will implement the padding  function for torch tensors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your Task:** Implement the function `PYTORCH_padding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PYTORCH_padding(X,pad_widths):\n",
    "\n",
    "    \"\"\"\n",
    "    This involves adding extra elements (usually zeros) around the edges of a tensor. \n",
    "    We will encounter this during convolutional operations to control the spatial dimensions of the output.\n",
    "    \n",
    "    Parameters:\n",
    "    X (torch.Tensor): input tensor which is to be padded.\n",
    "    pad_widths (tuple): even number of elements in tuple that represents padding widths in the order columns,rows and channels.\n",
    "\n",
    "    Returns: \n",
    "    torch.Tensor: stacked tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.nn.functional.pad(X, pad_widths) #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 6, 1, 0, 0],\n",
      "         [0, 0, 4, 4, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 8, 4, 0, 0],\n",
      "         [0, 0, 6, 3, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(1, 10, size=(2,2,2))\n",
    "\n",
    "X = numpy2tensor(X)\n",
    "\n",
    "\n",
    "print(PYTORCH_padding(X,(2,2,1,1,0,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"align:40%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\"><tt><b> PYTORCH_padding(X,pad_widths) </b></tt></td> \n",
    "        <td style=\"text-align:left;\"><tt>\n",
    "     [[[0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0],<br>\n",
    "&nbsp; [0,&nbsp;0,&nbsp;6,&nbsp;1,&nbsp;0,&nbsp;0], <br>\n",
    "&nbsp; [0,&nbsp;0,&nbsp;4,&nbsp;4,&nbsp;0,&nbsp;0], <br>\n",
    "&nbsp; [0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0]] <br>\n",
    "<br>\n",
    "&nbsp;[[0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0], <br>\n",
    "&nbsp; [0,&nbsp;0,&nbsp;8,&nbsp;4,&nbsp;0,&nbsp;0], <br>\n",
    "&nbsp; [0,&nbsp;0,&nbsp;6,&nbsp;3,&nbsp;0,&nbsp;0], <br>\n",
    "&nbsp; [0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0,&nbsp;0]]] \n",
    "        </tt></td> \n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('torch17')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a34e97cc6e2615ab92a28698ea9d0348d286f96a72c3605984746b76cc50ac7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
